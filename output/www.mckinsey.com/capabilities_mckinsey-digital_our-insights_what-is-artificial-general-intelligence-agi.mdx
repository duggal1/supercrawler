# What is artificial general intelligence (AGI)?

## What is needed for AI to become AGI?

## How will people access AGI tools?

## What is a robot and what types of robots are there?

## What advances could speed up the development of AGI?

## What can executives do about AGI?

## Pop quiz

### Looking for direct answers to other complex questions?

### Want to know more about artificial general intelligence (AGI)?

##### Get to know and directly engage with senior McKinsey experts on AGI

##### Related Articles

###### An executive primer on artificial general intelligence

###### What every CEO should know about generative AI

###### Notes from the AI frontier: Applications and value of deep learning

You’ve read the think pieces.  AI—in particular, the generative AI (gen AI) breakthroughs achieved in the past year or so—is poised to revolutionize not just the way we create content but the very makeup of our economies and societies as a whole. But although gen AI tools such as ChatGPT may seem like a great leap forward, in reality they are just a step in the direction of an even greater breakthrough: artificial general intelligence, or AGI.

Aamer Baig  is a senior partner in McKinsey’s Chicago office;  Federico Berruti  is a partner in the Toronto office;  Ben Ellencweig  is a senior partner in the Stamford, Connecticut, office;  Damian Lewandowski  is a consultant in the Miami office;  Roger Roberts  is a partner in the Bay Area office, where  Lareina Yee  is a senior partner;  Alex Singla  is a senior partner in the Chicago office and the global leader of QuantumBlack, AI by McKinsey;  Kate Smaje  and  Alex Sukharevsky  are senior partners in the London office;   Jonathan Tilley  is a partner in the Southern California office; and  Rodney Zemmel  is a senior partner in the New York office.

AGI is AI with  capabilities that rival those of a human . While purely theoretical at this stage, someday AGI may replicate human-like cognitive abilities including reasoning, problem solving, perception, learning, and language comprehension. When AI’s abilities are indistinguishable from those of a human, it will have passed what is known as the  Turing test , first proposed by 20th-century computer scientist Alan Turing.

But let’s not get ahead of ourselves. AI has made significant strides in recent years, but no AI tool to date has passed the Turing test. We’re still far from reaching a point where AI tools can understand, communicate, and act with the same nuance and sensitivity of a human—and, critically, understand the meaning behind it. Most researchers and academics believe we are decades away from realizing AGI; a few even predict we won’t see AGI this century (or ever). Rodney Brooks, a roboticist at the Massachusetts Institute of Technology and cofounder of iRobot, believes AGI won’t arrive until  the year 2300 .

If you’re thinking that AI already seems pretty smart, that’s understandable. We’ve seen  gen AI  do remarkable things in recent years, from writing code to composing sonnets in seconds. But there’s a critical difference between AI and AGI. Although the latest gen AI technologies, including ChatGPT, DALL-E, and others, have been hogging headlines, they are essentially prediction machines—albeit very good ones. In other words, they can predict, with a high degree of accuracy, the answer to a specific prompt because they’ve been trained on huge amounts of data. This is impressive, but it’s not at a human level of performance in terms of creativity, logical reasoning, sensory perception,  and other capabilities . By contrast, AGI tools could feature cognitive and emotional abilities (like empathy) indistinguishable from those of a human. Depending on your definition of AGI, they might even be capable of consciously grasping the meaning behind what they’re doing.

The timing of AGI’s emergence is uncertain. But when it does arrive—and it likely will at some point—it’s going to be a very big deal for every aspect of our lives, businesses, and societies. Executives can begin working now to better understand the path to machines achieving human-level intelligence and making the transition to a more automated world.

Learn more about  QuantumBlack, AI by McKinsey .

Here are eight capabilities AI needs to master before achieving AGI. Click each card to learn more.

Today, most people engage with AI in the same ways they’ve accessed digital power for years: via 2D screens such as laptops, smartphones, and TVs. The future will probably look a lot different. Some of the brightest minds (and biggest budgets) in tech are devoting themselves to figuring out how we’ll access AI (and possibly AGI) in the future. One example you’re likely familiar with is  augmented reality and virtual reality headsets , through which users experience an  immersive virtual world . Another example would be humans accessing the AI world through implanted neurons in the brain. This might sound like something out of a sci-fi novel, but it’s not. In January 2024, Neuralink  implanted  a chip in a human brain, with the goal of allowing the human to control a phone or computer purely by thought.

A final mode of interaction with AI seems ripped from sci-fi as well: robots. These can take the form of mechanized limbs connected to humans or machine bases or even programmed humanoid robots.

The simplest definition of a robot is a machine that can perform tasks on its own or with minimal assistance from humans. The most sophisticated robots can also interact with their surroundings.

Programmable robots have been operational since the 1950s. McKinsey estimates that 3.5 million robots are currently in use, with 550,000 more deployed every year. But while programmable robots are more commonplace than ever in the workforce, they have a long way to go before they outnumber their human counterparts. The Republic of Korea, home to the world’s highest density of robots, still employs 100 times as many humans as robots.

But as hardware and software limitations become increasingly surmountable, companies that manufacture robots are beginning to program units with new AI tools and techniques. These dramatically improve robots’ ability to perform tasks typically handled by humans, including walking, sensing, communicating, and manipulating objects. In May 2023, Sanctuary AI, for example,  launched  Phoenix, a bipedal humanoid robot that stands 5’ 7” tall, lifts objects weighing as much as 55 pounds, and travels three miles per hour—not to mention it also folds clothes, stocks shelves, and works a register.

As we edge closer to AGI, we can expect increasingly sophisticated AI tools and techniques to be programmed into robots of all kinds. Here are a few categories of robots that are currently operational:

Learn more about  QuantumBlack, AI by McKinsey .

Advances in  algorithms, computing, and data  have brought about the recent acceleration of AI. We can get a sense of what the future may hold by looking at these three capabilities:

Algorithmic advances and new robotics approaches . We may need entirely new approaches to algorithms and robots to achieve AGI. One way researchers are thinking about this is by exploring the concept of embodied cognition. The idea is that robots will need to learn very quickly from their environments through a multitude of senses, just like humans do when they’re very young. Similarly, to develop cognition in the same way humans do, robots will need to experience the physical world like we do (because we’ve designed our spaces based on how our bodies and minds work).

The latest AI-based robot systems are using gen AI technologies including large language models (LLMs) and large behavior models (LBMs). LLMs give robots advanced natural-language-processing capabilities like what we’ve seen with generative AI models and other LLM-enabled tools. LBMs allow robots to emulate human actions and movements. These models are created by training AI on large data sets of observed human actions and movements. Ultimately, these models could allow robots to perform a wide range of activities with limited task-specific training.

A real advance would be to develop new AI systems that start out with a certain level of built-in knowledge, just like a baby fawn knows how to stand and feed without being taught. It’s possible that the recent success of deep-learning-based AI systems may have drawn research attention away from the more fundamental cognitive work required to make progress toward AGI.

Growth in data volume and new sources of data . Some experts believe  5G  mobile infrastructure could bring about a significant increase in data. That’s because the technology could power a surge in connected devices, or the  Internet of Things . But, for a variety of reasons, we think most of the benefits of 5G have  already appeared . For AGI to be achieved, there will need to be another catalyst for a huge increase in data volume.

New robotics approaches could yield new sources of training data. Placing human-like robots among us could allow companies to mine large sets of data that mimic our own senses to help the robots train themselves. Advanced self-driving cars are one example: data is being collected from cars that are already on the roads, so these vehicles are acting as a training set for future self-driving cars.

AGI is still decades away, at the very least. But AI is here to stay—and it is advancing extremely quickly. Smart leaders can think about how to respond to the real progress that’s happening, as well as how to prepare for the automated future. Here are a few things to consider:

Learn more about  QuantumBlack, AI by McKinsey . And check out  AI-related job opportunities  if you’re interested in working at McKinsey.

Articles referenced:

Talk to us